{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-02-14-Pytorchtofastai.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65dXi15WswOz"
      },
      "source": [
        "# Pytorch to fastai, Bridging the Gap\r\n",
        "> Understanding how to bring Pytorch code into the fastai space with minimal headache\r\n",
        "\r\n",
        "* toc: true\r\n",
        "* badges: true\r\n",
        "* comments: true"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "6mDXFUG4sopG",
        "outputId": "09e66e61-8d5d-4463-e871-ba3014e08e49"
      },
      "source": [
        "#hide_input\r\n",
        "from wwf.utils import state_versions\r\n",
        "state_versions(['fastai', 'fastcore', 'torch', 'torchvision'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/markdown": "\n---\nThis article is also a Jupyter Notebook available to be run from the top down. There\nwill be code snippets that you can then run in any environment.\n\nBelow are the versions of `fastai`, `fastcore`, `torch`, and `torchvision` currently running at the time of writing this:\n* `fastai`: 2.2.5 \n* `fastcore`: 1.3.19 \n* `torch`: 1.7.0+cu101 \n* `torchvision`: 0.8.1+cu101 \n---",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmGxazFVtp1a"
      },
      "source": [
        "## Addressing the Elephant in the Room\r\n",
        "\r\n",
        "I recently posted a [tweet](https://twitter.com/TheZachMueller/status/1359584461873111044?s=20) asking about what people struggle with the most in `fastai`, and the resounding answer was how to integrate *minimally* with Pytorch. An impression seems to have been made that to use `fastai` you *must* use the complete `fastai` API only, and nothing else.\r\n",
        "\r\n",
        "Let's clear up that misconception now:\r\n",
        "\r\n",
        "> Important: `fastai` at its core is a *training* loop, designed to be framework agnostic. You can use any flavor of Pytorch you want, and only use `fastai` to quickly and effictively train a model with state-of-the-art practices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INxoBxBEuy0o"
      },
      "source": [
        "## The Plan\r\n",
        "\r\n",
        "Now that the misconceptions have been addressed, let's walk through just how that is going to happen. We're going to follow the official Pytorch [CIFAR10](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) tutorial and show what needs to minimally happen in the `fastai` framework to take full advantage of the `Learner`. This will include:\r\n",
        "\r\n",
        "* The `Dataset`\r\n",
        "* The `DataLoaders`\r\n",
        "* The model\r\n",
        "* The optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XozNR3Acvfnk"
      },
      "source": [
        "## The Dataset and DataLoaders\r\n",
        "\r\n",
        "Following from the tutorial, we're going to load in the dataset using only torchvision. First we'll grab our imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGaGdX3DtLr6"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrtvsAftvsSD"
      },
      "source": [
        "Next we're going to definine some minimal transforms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP02xowOvrMs"
      },
      "source": [
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lnrhNj0v2qA"
      },
      "source": [
        "Before downloading our train and test sets:\r\n",
        "\r\n",
        "> Note: I'm using naming conventions similar to how `fastai` names things, so you can see how these can relate to each other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNHLOjJIv1uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59787027-1040-408a-f7ce-be4765cb0c0a"
      },
      "source": [
        "dset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\r\n",
        "                                        download=True, transform=transform)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La_ik28xv7tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2a74e5-3a75-4b55-e2d1-398f1ad46ac2"
      },
      "source": [
        "dset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\r\n",
        "                                       download=True, transform=transform)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6-8LaXxwBH7"
      },
      "source": [
        "Next we'll make our `Dataloaders`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH9tRI9mv9il"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=4,\r\n",
        "                                          shuffle=True, num_workers=2)\r\n",
        "testloader = torch.utils.data.DataLoader(dset_test, batch_size=4,\r\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H95wBO6NxA93"
      },
      "source": [
        "And that's as far as we'll go from there for now, let's move onto the model next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20YObXfKxJHF"
      },
      "source": [
        "## The Model\r\n",
        "\r\n",
        "We'll bring in the architecture from the tutorial and use it here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2SI6qIvwwvN"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrXOQM5CxRYh"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "        self.pool = nn.MaxPool2d(2, 2)\r\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\r\n",
        "        self.fc2 = nn.Linear(120, 84)\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        x = x.view(-1, 16 * 5 * 5)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Laz5IjnvxVTT"
      },
      "source": [
        "And finally we'll make an instance of it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC9Fc6A-xU96"
      },
      "source": [
        "net = Net()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9UHaR2ixZJE"
      },
      "source": [
        "## Loss Function and Optimizer\r\n",
        "\r\n",
        "Next we'll bring in their loss function and optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQQzHKxczMgH"
      },
      "source": [
        "The loss function is simple enough:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54jt7ghrzOiP"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cElIjZjrzO6p"
      },
      "source": [
        "However the optimizer requires a *little* bit of `fastai` magic, specifically in the form of an `OptimWrapper`. Our optimizer function should be defined as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaBZiuQKza4o"
      },
      "source": [
        "from fastai.optimizer import OptimWrapper\r\n",
        "from torch import optim"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA6xlSYMNhbo"
      },
      "source": [
        "def opt_func(params, **kwargs): return OptimWrapper(params, torch.optim.SGD, **kwargs)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hhl0PstxqgY"
      },
      "source": [
        "## Training\r\n",
        "\r\n",
        "Now we have everything needed to train a model, so now let's bring in `fastai`'s training loop, also known as the `Learner`. \r\n",
        "\r\n",
        "`fastai`'s `Learner` expects `DataLoaders` to be used, rather than simply one `DataLoader`, so let's make that:\r\n",
        "\r\n",
        "> Note: fastai also expects a validation `DataLoader` to be present, so we'll be tying the `testloader` in here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElZ85UkqxkBV"
      },
      "source": [
        "from fastai.data.core import DataLoaders"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCJuAvO7x8U1"
      },
      "source": [
        "dls = DataLoaders(trainloader, testloader)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abX2Y3YdyXrq"
      },
      "source": [
        "Finally we're going to wrap it all up in a `Learner`. As mentioned before, the `Learner` is the glue that merges everything together and enables users to utilize Leslie Smith's One-Cycle Policy, the learning rate finder, and other `fastai` training goodies. \r\n",
        "\r\n",
        "Let's make it by passing in our `dls`, the model, the optimizer, and the loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t9OdBCWyt0s"
      },
      "source": [
        "from fastai.learner import Learner"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChplJ57LMspD"
      },
      "source": [
        "To get `fastai`'s fancy-looking progress bar, we need to import the `ProgressCallback`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v6vrG9IMtT_"
      },
      "source": [
        "from fastai.callback.progress import ProgressCallback"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8k6kxNeMqZr"
      },
      "source": [
        "We also need to pass in the `CudaCallback` so our batches can be pushed to the GPU (`fastai`'s `DataLoaders` can do this automatically)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIRQz4OXMxym"
      },
      "source": [
        "from fastai.callback.data import CudaCallback"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-StN4PyjlS"
      },
      "source": [
        "learn = Learner(dls, net, loss_func=criterion, opt_func=opt_func, cbs=[CudaCallback])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvhbhwyFyyIr"
      },
      "source": [
        "Finally, let's do some minimal training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oImZWuqWy7xz"
      },
      "source": [
        "Now we have everything needed to do a basic `fit`:\r\n",
        "> Note: Since we already passed in a learning rate to `Learner` we don't need to pass one in here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "e7tOMYCv8G4j",
        "outputId": "0561366a-74fe-41d1-a595-745a24bb638b"
      },
      "source": [
        "learn.fit(2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.265952</td>\n",
              "      <td>2.263797</td>\n",
              "      <td>01:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.867355</td>\n",
              "      <td>1.866925</td>\n",
              "      <td>01:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a-gVGQ8-_Bb"
      },
      "source": [
        "## What's Next?\r\n",
        "\r\n",
        "Great, so now we've trained our model, but what do we do with it? How do I get it out?\r\n",
        "\r\n",
        "Your model lives in `learn.model`, and we've already seen that we passed in a regular Pytorch model earlier. Since we're using fastai's base `Learner` class, the model itself was untouched. As a result, it's *still* a regular Pytorch model we can save away:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNadx035-ROp"
      },
      "source": [
        "torch.save(learn.model.state_dict(), './cifar_net.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiTZcrEK_TZt"
      },
      "source": [
        "And that's really it! As you can see, the minimalist you can *absolutely* get with using the fastai framework is:\r\n",
        "\r\n",
        "* `Pytorch` `DataLoader`\r\n",
        "* `Pytorch` model\r\n",
        "* `fastai` `Learner`\r\n",
        "* `fastai` `Optimizer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW6Tj2_u_hov"
      },
      "source": [
        "## Closing Remarks\r\n",
        "\r\n",
        "I hope this has enlightned you on just how flexible the fastai framework can truly be for your training needs with the idealistic goal of simply *getting a model out there*.\r\n",
        "\r\n",
        "As we've removed most of the fastai magic, from here on out you should be utilizing standard Pytorch, as fastai specific functions like `test_dl` and `predict` will no longer be able to be used, as you didn't use a `fastai` DataLoader.\r\n",
        "\r\n",
        "Thank you for reading!"
      ]
    }
  ]
}
